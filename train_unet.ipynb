{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42643c51-3b7b-4956-8574-75e6ab1cb5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"GPU detectada:\", gpus)\n",
    "    except RuntimeError as e:\n",
    "        print(\"Error en la configuración de GPU:\", e)\n",
    "else:\n",
    "    print(\"No se detectó GPU. TensorFlow está usando CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31dba59-6eb2-4a27-ad55-27561150b054",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices(gpus[0], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e06251-bc31-4b20-9e6f-d5b2d5ba053a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from pathlib import Path\n",
    "\n",
    "path = Path('./DATASET2')\n",
    "\n",
    "## Train\n",
    "trainimgs = [str(path/'Train_images'/i) for i in os.listdir(path/'Train_images')]\n",
    "trainmasks = [str(path/'Train_masks'/i) for i in os.listdir(path/'Train_masks')]\n",
    "train_data = list(zip(trainimgs, trainmasks))\n",
    "\n",
    "## Val\n",
    "valimgs = [str(path/'Val_images'/i) for i in os.listdir(path/'Val_images')]\n",
    "valmasks = [str(path/'Val_masks'/i) for i in os.listdir(path/'Val_masks')]\n",
    "val_data = list(zip(valimgs, valmasks))\n",
    "\n",
    "## Test\n",
    "testimgs = [str(path/'Test_images'/i) for i in os.listdir(path/'Test_images')]\n",
    "testmasks = [str(path/'Test_masks'/i) for i in os.listdir(path/'Test_masks')]\n",
    "test_data = list(zip(testimgs, testmasks))\n",
    "\n",
    "print(' - Train Set')\n",
    "print('Número de imágenes en train:', len(trainimgs))\n",
    "print('Número de máscaras en train:', len(trainmasks))\n",
    "print()\n",
    "print(' - Val Set')\n",
    "print('Número de imágenes en val:', len(valimgs))\n",
    "print('Número de máscaras en val:', len(valmasks))\n",
    "print()\n",
    "print(' - Test Set')\n",
    "print('Número de imágenes en test:', len(testimgs))\n",
    "print('Número de mascaras en test:', len(testmasks))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c56ccbe-20bd-4f8f-ad01-a812a7c7efb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Fijar la semilla\n",
    "tf.random.set_seed(123)\n",
    "\n",
    "# Tamaños entrada y número de categorías\n",
    "img_size = (256,256,3) # El tamaño de cada patch\n",
    "nclases = 1\n",
    "\n",
    "# ===============\n",
    "# Entrada\n",
    "entrada = tf.keras.Input(shape=img_size)\n",
    "\n",
    "# ===============\n",
    "# Codificador\n",
    "\n",
    "# conv1\n",
    "conv1 = layers.Conv2D(16,(3,3),activation='relu',padding='same')(entrada)\n",
    "conv1 = layers.Conv2D(16,(3,3),activation='relu',padding='same')(conv1)\n",
    "pool1 = layers.MaxPool2D((2,2))(conv1)\n",
    "\n",
    "# conv2\n",
    "conv2 = layers.Conv2D(32,(3,3),activation='relu',padding='same')(pool1)\n",
    "conv2 = layers.Conv2D(32,(3,3),activation='relu',padding='same')(conv2)\n",
    "pool2 = layers.MaxPool2D((2,2))(conv2)\n",
    "\n",
    "# conv3\n",
    "conv3 = layers.Conv2D(64,(3,3),activation='relu',padding='same')(pool2)\n",
    "conv3 = layers.Conv2D(64,(3,3),activation='relu',padding='same')(conv3)\n",
    "pool3 = layers.MaxPool2D((2,2))(conv3)\n",
    "\n",
    "# conv4\n",
    "conv4 = layers.Conv2D(128,(3,3),activation='relu',padding='same')(pool3)\n",
    "conv4 = layers.Conv2D(128,(3,3),activation='relu',padding='same')(conv4)\n",
    "pool4 = layers.MaxPool2D((2,2))(conv4)\n",
    "\n",
    "# conv5\n",
    "conv5 = layers.Conv2D(256,(3,3),activation='relu',padding='same')(pool4)\n",
    "conv5 = layers.Conv2D(256,(3,3),activation='relu',padding='same')(conv5)\n",
    "\n",
    "# ===============\n",
    "# Decodificador\n",
    "\n",
    "# dec1\n",
    "dec1 = layers.Conv2DTranspose(128, (2,2), strides=(2,2), padding='same')(conv5)\n",
    "dec1 = layers.concatenate([dec1,conv4])\n",
    "dec1 = layers.Conv2DTranspose(128, (3,3), activation='relu', padding='same')(dec1)\n",
    "dec1 = layers.Conv2DTranspose(128, (3,3), activation='relu', padding='same')(dec1)\n",
    "\n",
    "# dec2\n",
    "dec2 = layers.Conv2DTranspose(64, (2,2), strides=(2,2), padding='same')(dec1)\n",
    "dec2 = layers.concatenate([dec2,conv3])\n",
    "dec2 = layers.Conv2DTranspose(64, (3,3), activation='relu', padding='same')(dec2)\n",
    "dec2 = layers.Conv2DTranspose(64, (3,3), activation='relu', padding='same')(dec2)\n",
    "\n",
    "# dec3\n",
    "dec3 = layers.Conv2DTranspose(32, (2,2), strides=(2,2), padding='same')(dec2)\n",
    "dec3 = layers.concatenate([dec3,conv2])\n",
    "dec3 = layers.Conv2DTranspose(32, (3,3), activation='relu', padding='same')(dec3)\n",
    "dec3 = layers.Conv2DTranspose(32, (3,3), activation='relu', padding='same')(dec3)\n",
    "\n",
    "# dec4\n",
    "dec4 = layers.Conv2DTranspose(16, (2,2), strides=(2,2), padding='same')(dec3)\n",
    "dec4 = layers.concatenate([dec4,conv1])\n",
    "dec4 = layers.Conv2DTranspose(16, (3,3), activation='relu', padding='same')(dec4)\n",
    "dec4 = layers.Conv2DTranspose(16, (3,3), activation='relu', padding='same')(dec4)\n",
    "\n",
    "# ===============\n",
    "# Salida\n",
    "salida = layers.Conv2D(filters=1, kernel_size=(1,1), activation='sigmoid')(dec4)\n",
    "# ===============\n",
    "# Interconectar todo en un modelo\n",
    "unet = tf.keras.models.Model(inputs=entrada, outputs=salida)\n",
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99710e29-45ec-43ae-9019-c4c0523eab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdb15b5-579f-455e-a84f-7b50169976c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', dice_coef]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d8f9ed-6456-41c5-af23-c1b891e428d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si las rutas están en formato Path, conviértelas a cadenas.\n",
    "trainimgs = [str(img) for img in trainimgs]\n",
    "trainmasks = [str(msk) for msk in trainmasks]\n",
    "valimgs = [str(img) for img in valimgs]\n",
    "valmasks = [str(msk) for msk in valmasks]\n",
    "testimgs = [str(img) for img in testimgs]\n",
    "testmasks = [str(msk) for msk in testmasks]\n",
    "\n",
    "trainimgs, trainmasks = zip(*train_data)\n",
    "valimgs, valmasks = zip(*val_data)\n",
    "testimgs, testmasks = zip(*test_data)\n",
    "\n",
    "trainimgs = list(trainimgs)\n",
    "trainmasks = list(trainmasks)\n",
    "valimgs = list(valimgs)\n",
    "valmasks = list(valmasks)\n",
    "testimgs = list(testimgs)\n",
    "testmasks = list(testmasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3702b4a3-eb0c-4ea8-869f-941fc804aa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora crea los datasets como lo mencionamos antes\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((trainimgs, trainmasks))\n",
    "ds_train = ds_train.shuffle(buffer_size=1000).batch(32)\n",
    "\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((valimgs, valmasks))\n",
    "ds_val = ds_val.batch(32)\n",
    "\n",
    "ds_test = tf.data.Dataset.from_tensor_slices((testimgs, testmasks))\n",
    "ds_test = ds_test.batch(32)\n",
    "\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "\n",
    "# Fijar directorios para las imágenes y las máscaras\n",
    "DIR_IMGS = Path('./DATASET/Train_images/')\n",
    "DIR_MSKS = Path('./DATASET/Train_mask/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8106651-a2ed-409b-b9b5-8e4094524964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La función para lectura y pre-procesamiento\n",
    "def preprocesar_imagen(imgpath, mskpath):\n",
    "    # Crear rutas completas a partir de las rutas relativas\n",
    "    # Leer las imágenes y las máscaras como archivos\n",
    "    img = tf.io.read_file(imgpath)  # Ahora imgpath es una cadena\n",
    "    msk = tf.io.read_file(mskpath)  # Ahora mskpath es una cadena\n",
    "\n",
    "    img = tf.image.decode_jpeg(img, channels=3)  # uint8\n",
    "    msk = tf.image.decode_png(msk, channels=1)   # uint8\n",
    "\n",
    "    img = tf.image.convert_image_dtype(img, dtype=tf.float32) \n",
    "\n",
    "    msk = tf.image.convert_image_dtype(msk, dtype=tf.float32)\n",
    "\n",
    "    return img, msk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b3e447-bc67-4059-b6f2-791ff1130468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar preprocesamiento y crear los lotes\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((trainimgs, trainmasks))\n",
    "ds_train = ds_train.map(lambda img, msk: preprocesar_imagen(img, msk))  # Mapeamos el preprocesamiento\n",
    "ds_train = ds_train.shuffle(buffer_size=1000).batch(32)\n",
    "\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((valimgs, valmasks))\n",
    "ds_val = ds_val.map(lambda img, msk: preprocesar_imagen(img, msk))  # Mapeamos el preprocesamiento\n",
    "ds_val = ds_val.batch(32)\n",
    "\n",
    "ds_test = tf.data.Dataset.from_tensor_slices((testimgs, testmasks))\n",
    "ds_test = ds_test.map(lambda img, msk: preprocesar_imagen(img, msk))  # Mapeamos el preprocesamiento\n",
    "ds_test = ds_test.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72a323c-37f1-4acd-9b33-f0f6e76c61fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y entrenar el modelo: ¡en este punto SÍ se leen las imágenes!\n",
    "print (\"Comenzando entrenamiento\")\n",
    "\n",
    "history = unet.fit(ds_train, validation_data = ds_val, epochs=200, verbose=2)\n",
    "\n",
    "print (\"Entrenamiento finalizado con éxito\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9522c2dd-104d-4385-ae71-529b11e854f6",
   "metadata": {},
   "source": [
    "## Guardado de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eecc42-5c06-43a2-a063-5b4a67338f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.save(('Modelo_Final.keras'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb45374-228e-4c69-b54f-3d038fdc6263",
   "metadata": {},
   "source": [
    "## Prueba del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7cc8ee-7830-48fc-b704-c0afefe49ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel(\"# Epoca\")\n",
    "plt.ylabel(\"Magnitud de pérdida\")\n",
    "plt.plot(history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2f58e3-2566-4b85-a14c-1003d56b0725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Obtener una imagen del dataset de validación\n",
    "for img, msk in ds_val.take(1):\n",
    "    pred = unet.predict(img)\n",
    "\n",
    "    for i in range(3):  # Mostrar 3 ejemplos\n",
    "        plt.figure(figsize=(12,4))\n",
    "        \n",
    "        plt.subplot(1,3,1)\n",
    "        plt.title(\"Imagen\")\n",
    "        plt.imshow(img[i])\n",
    "        \n",
    "        plt.subplot(1,3,2)\n",
    "        plt.title(\"Máscara real\")\n",
    "        plt.imshow(msk[i,...,0], cmap='gray')\n",
    "        \n",
    "        plt.subplot(1,3,3)\n",
    "        plt.title(\"Predicción\")\n",
    "        plt.imshow(pred[i,...,0], cmap='gray')\n",
    "        \n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26938e43-63bd-4691-b59d-2ef784113b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
