{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c8cc98b-7a57-4d2b-bc83-a58709cf3498",
   "metadata": {},
   "source": [
    "# SCRIPT DE GENERACIÓN Y PARTICIÓN DEL DATASET\n",
    "\n",
    "Este script organiza las imágenes aumentadas en una estructura de directorios estándar para entrenamiento de Deep Learning. Divide los datos aleatoriamente en tres subconjuntos:\n",
    "- Train (Entrenamiento): Para ajustar los pesos del modelo.\n",
    "- Val (Validación): Para ajustar hiperparámetros y monitorear el overfitting.\n",
    "- Test (Prueba): Para la evaluación final con datos inéditos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675e41ac-3e6a-4aaf-abdb-cb318478682a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# === CONFIGURACIÓN DE RUTAS Y PARÁMETROS ===\n",
    "# Directorios de origen (donde guardaste las imágenes aumentadas)\n",
    "IMAGES_DIR = 'Aum_images'\n",
    "MASKS_DIR = 'Aum_masks'\n",
    "\n",
    "# Directorio base de salida (se creará si no existe)\n",
    "OUTPUT_BASE = 'dataset'\n",
    "\n",
    "# Proporciones de división del dataset (Debe sumar 1.0)\n",
    "# 70% Entrenamiento, 25% Validación, 5% Prueba\n",
    "SPLIT_RATIOS = {'train': 0.7, 'val': 0.25, 'test': 0.05}\n",
    "\n",
    "def split_dataset():\n",
    "    \"\"\"\n",
    "    Ejecuta la partición aleatoria y copia los archivos a las carpetas de destino.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Obtener y barajar la lista de archivos\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Filtramos solo archivos de imagen para evitar archivos ocultos o de sistema\n",
    "    image_files = sorted([f for f in os.listdir(IMAGES_DIR) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "    \n",
    "    # Establecemos una semilla (seed) para que la mezcla sea reproducible.\n",
    "    # Si ejecutas este script dos veces, la división será idéntica.\n",
    "    random.seed(42) \n",
    "    random.shuffle(image_files)\n",
    "\n",
    "    # 2. Calcular los índices de corte\n",
    "    # -------------------------------------------------------------------------\n",
    "    total = len(image_files)\n",
    "    num_train = int(total * SPLIT_RATIOS['train'])\n",
    "    num_val = int(total * SPLIT_RATIOS['val'])\n",
    "    # El resto se asigna a test para asegurar que no se pierda ningún archivo por redondeo\n",
    "    num_test = total - num_train - num_val\n",
    "\n",
    "    print(f\"Total imágenes encontradas: {total}\")\n",
    "    print(f\"Distribución -> Train: {num_train}, Val: {num_val}, Test: {num_test}\")\n",
    "\n",
    "    # Diccionario con las listas de archivos para cada set\n",
    "    splits = {\n",
    "        'train': image_files[:num_train],\n",
    "        'val': image_files[num_train:num_train + num_val],\n",
    "        'test': image_files[num_train + num_val:]\n",
    "    }\n",
    "\n",
    "    # 3. Crear estructura de carpetas y copiar archivos\n",
    "    # -------------------------------------------------------------------------\n",
    "    for split_name, files in splits.items():\n",
    "        print(f\"\\nProcesando conjunto: {split_name.upper()}...\")\n",
    "        \n",
    "        # Crear directorios: dataset/train/images, dataset/train/masks, etc.\n",
    "        # makedirs con exist_ok=True evita errores si la carpeta ya existe\n",
    "        os.makedirs(os.path.join(OUTPUT_BASE, split_name, 'images'), exist_ok=True)\n",
    "        os.makedirs(os.path.join(OUTPUT_BASE, split_name, 'masks'), exist_ok=True)\n",
    "\n",
    "        for fname in files:\n",
    "            # --- Procesamiento de la IMAGEN ---\n",
    "            src_img = os.path.join(IMAGES_DIR, fname)\n",
    "            dst_img = os.path.join(OUTPUT_BASE, split_name, 'images', fname)\n",
    "            \n",
    "            # Copiar imagen al destino\n",
    "            shutil.copyfile(src_img, dst_img)\n",
    "\n",
    "            # --- Procesamiento de la MÁSCARA ---\n",
    "            # Asumimos que la máscara tiene el mismo nombre base que la imagen\n",
    "            # pero con extensión .png (formato sin pérdida para etiquetas)\n",
    "            base_name = os.path.splitext(fname)[0]\n",
    "            \n",
    "            # NOTA: Si tus máscaras tienen otro sufijo (ej: _mask.png), ajusta esta línea\n",
    "            mask_name = base_name + '.png' \n",
    "\n",
    "            src_mask = os.path.join(MASKS_DIR, mask_name)\n",
    "            dst_mask = os.path.join(OUTPUT_BASE, split_name, 'masks', mask_name)\n",
    "\n",
    "            # Verificación de seguridad: ¿Existe la máscara correspondiente?\n",
    "            if not os.path.exists(src_mask):\n",
    "                print(f\" [ADVERTENCIA] Máscara no encontrada para {fname}. Se omite este par.\")\n",
    "                # Si falta la máscara, podríamos borrar la imagen copiada para no ensuciar el dataset\n",
    "                # os.remove(dst_img) \n",
    "                continue\n",
    "\n",
    "            # Copiar máscara al destino\n",
    "            shutil.copyfile(src_mask, dst_mask)\n",
    "\n",
    "    print(f\"\\nProceso finalizado. Dataset generado en la carpeta '{OUTPUT_BASE}'.\")\n",
    "\n",
    "# === EJECUCIÓN PRINCIPAL ===\n",
    "if __name__ == \"__main__\":\n",
    "    # Verificar que los directorios de entrada existan antes de empezar\n",
    "    if os.path.exists(IMAGES_DIR) and os.path.exists(MASKS_DIR):\n",
    "        split_dataset()\n",
    "    else:\n",
    "        print(\"Error: No se encuentran los directorios de entrada (Aum_images / Aum_masks).\")\n",
    "        print(\"Ejecuta primero el script de Data Augmentation.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
